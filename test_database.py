#!/usr/bin/env python3
"""æµ‹è¯•PostgreSQLæ•°æ®åº“è¿æ¥å’ŒåŸºæœ¬æ“ä½œ"""

import asyncio
import sys
import os

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

from backend.database import test_db_connection, init_database
from backend.db_service import ConversationService, MessageService, KnowledgeService

async def test_database_operations():
    """æµ‹è¯•æ•°æ®åº“åŸºæœ¬æ“ä½œ"""
    print("ğŸ§ª æµ‹è¯•PostgreSQLæ•°æ®åº“æ“ä½œ...")

    # æµ‹è¯•è¿æ¥
    if not await test_db_connection():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥PostgreSQLæ˜¯å¦è¿è¡Œ")
        return

    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_database()

        # æµ‹è¯•åˆ›å»ºå¯¹è¯
        print("\nğŸ“ æµ‹è¯•åˆ›å»ºå¯¹è¯...")
        from backend.database import get_async_db

        async for db in get_async_db():
            # åˆ›å»ºæµ‹è¯•å¯¹è¯
            conversation = await ConversationService.create_conversation(
                db,
                title="æµ‹è¯•å¯¹è¯ - æ•°æ®åº“é›†æˆ"
            )
            print(f"âœ… åˆ›å»ºå¯¹è¯æˆåŠŸ: {conversation.id} - {conversation.title}")

            # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
            user_message = await MessageService.create_message(
                db,
                conversation_id=conversation.id,
                role="user",
                content="ä»€ä¹ˆæ˜¯Pythonï¼Ÿè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ã€‚"
            )
            print(f"âœ… åˆ›å»ºç”¨æˆ·æ¶ˆæ¯æˆåŠŸ: {user_message.id}")

            # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯
            assistant_message = await MessageService.create_message(
                db,
                conversation_id=conversation.id,
                role="assistant",
                content="Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...",
                stage1_responses=[
                    {"model": "openai/gpt-4", "response": "Pythonæ˜¯Guido van Rossumåˆ›å»ºçš„ç¼–ç¨‹è¯­è¨€"},
                    {"model": "anthropic/claude-3", "response": "Pythonæ˜¯ä¸€ç§è§£é‡Šå‹ã€é«˜çº§ç¼–ç¨‹è¯­è¨€"}
                ],
                stage2_rankings=[
                    {"model": "openai/gpt-4", "ranking": "1. Response A\\n2. Response B"}
                ],
                stage3_response={
                    "model": "gemini/gemini-pro",
                    "response": "ç»¼åˆæ¥çœ‹ï¼ŒPythonæ˜¯ä¸€ç§ç®€æ´è€Œå¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€"
                }
            )
            print(f"âœ… åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯æˆåŠŸ: {assistant_message.id}")

            # åˆ›å»ºçŸ¥è¯†åº“æ¡ç›®
            knowledge_entry = await KnowledgeService.create_knowledge_entry(
                db,
                title="Pythonç¼–ç¨‹è¯­è¨€ä»‹ç»",
                content="Pythonæ˜¯ä¸€ç§ç®€æ´çš„é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”±Guido van Rossumäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚å®ƒå…·æœ‰æ¸…æ™°çš„è¯­æ³•å’Œä¸°å¯Œçš„æ ‡å‡†åº“ï¼Œå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚",
                conversation_id=conversation.id,
                message_id=assistant_message.id,
                tags=["Python", "ç¼–ç¨‹è¯­è¨€", "å…¥é—¨æ•™ç¨‹"]
            )
            print(f"âœ… åˆ›å»ºçŸ¥è¯†åº“æ¡ç›®æˆåŠŸ: {knowledge_entry.id}")

            # æµ‹è¯•æŸ¥è¯¢
            print("\nğŸ” æµ‹è¯•æŸ¥è¯¢æ“ä½œ...")
            conversations = await ConversationService.list_conversations(db)
            print(f"âœ… æŸ¥è¯¢åˆ° {len(conversations)} ä¸ªå¯¹è¯")

            knowledge_entries = await KnowledgeService.list_knowledge_entries(db)
            print(f"âœ… æŸ¥è¯¢åˆ° {len(knowledge_entries)} ä¸ªçŸ¥è¯†åº“æ¡ç›®")

            # æµ‹è¯•æœç´¢
            search_results = await KnowledgeService.search_knowledge_entries(db, "Python")
            print(f"âœ… æœç´¢'Python'æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")

            print("\nğŸ‰ æ•°æ®åº“æ“ä½œæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
            break

    except Exception as e:
        print(f"âŒ æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_database_operations())